from sentence_transformers import SentenceTransformer
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
import chromadb 
from chromadb.config import Settings 
import string
import re 
from dotenv import load_dotenv
import os
from openai import OpenAI

load_dotenv(dotenv_path="openai.env")
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# Ä°lk kullanÄ±mda bu iki satÄ±rÄ± Ã§alÄ±ÅŸtÄ±r (bir kereye mahsus)
# nltk.download("punkt")
# nltk.download("stopwords")

# TÃ¼rkÃ§e stopwords listesi
stop_words = set(stopwords.words("turkish"))

# CÃ¼mledeki stopwords'leri temizleyen fonksiyon
def temizle_stopwords(cumle):
    cumle = cumle.lower()  #Hepsini kÃ§Ã¼k harfe Ã§eviriyor
    cumle = re.sub(r"[^\w\s]", "", cumle)  # Noktalama iÅŸaretlerini ve Ã¶zel karakterleri kaldÄ±r
    kelimeler = word_tokenize(cumle, language='turkish')
    temiz = [kelime for kelime in kelimeler if kelime not in stop_words and kelime.isalpha()]
    return " ".join(temiz)

def API_ILE_CEVAP_AL(soru):
    """OpenAI API kullanarak teknik sorulara kÄ±sa ve net cevaplar dÃ¶ner"""
    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {
                    "role": "system",
                    "content": (
                        "Sen bir teknik yapay zekasÄ±n. "
                        "Sadece yazÄ±lÄ±m, programlama, yapay zeka, siber gÃ¼venlik gibi teknik konularda gelen sorulara cevap ver. "
                        "CevaplarÄ±n kÄ±sa, net, doÄŸrudan ve teknik dille yazÄ±lmalÄ±. Gereksiz aÃ§Ä±klama, Ã¶neri veya selamlaÅŸma ekleme. "
                        "EÄŸer gelen soru teknik deÄŸilse, 'Bu sistem yalnÄ±zca teknik sorulara cevap verir.' yanÄ±tÄ±nÄ± ver."
                    )
                },
                {"role": "user", "content": soru}
            ],
            temperature=0.3,
            max_tokens=300
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        return f"Hata oluÅŸtu: {str(e)}"

def veritabani_kontrol(collection):
    # VeritabanÄ±ndaki kayÄ±tlarÄ± kontrol eder ve istatistikleri gÃ¶sterir.
    try:
        count = collection.count()
        print(f"\nğŸ” VeritabanÄ± Durumu: {count} kayÄ±t bulunuyor")
        
        if count > 0:
            results = collection.peek(limit=count)
            print("\nÃ–rnek KayÄ±tlar:")
            for doc, meta in zip(results['documents'], results['metadatas']):
                print(f"- Soru: {doc} | Cevap: {meta['cevap']}")
        return True
    except Exception as e:
        print(f"VeritabanÄ± kontrol hatasÄ±: {e}")
        return False

def veritabani_temizle(client, collection_name="soru_cevaplar"):
    """Belirtilen koleksiyonu tamamen siler"""
    try:
        client.delete_collection(name=collection_name)
        print(f"\nğŸ—‘ '{collection_name}' koleksiyonu tamamen silindi")
        return True
    except Exception as e:
        print(f"Silme hatasÄ±: {e}")
        return False

# Model yÃ¼kleme
model = SentenceTransformer("sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")

# Chroma istemcisi
try:
    chroma_client = chromadb.HttpClient(host="localhost", port=8000)
    # Koleksiyon oluÅŸtur (eÄŸer yoksa)
    collection = chroma_client.get_or_create_collection(
        name="soru_cevaplar",
        metadata={"hnsw:space": "cosine"}  # Cosine similarity kullan
    )
    
    # VeritabanÄ± durumunu kontrol et
    # veritabani_kontrol(collection)
    
except Exception as e:
    print(f"ChromaDB baÄŸlantÄ± hatasÄ±: {e}")
    exit()

# Soru-cevap veri seti (ilk defa aÃ§Ä±lÄ±ÅŸ iÃ§in)
data = {
    "soru": [
        "Makine Ã¶ÄŸrenmesi nedir?",
        "Denetimli Ã¶ÄŸrenme ne demektir?",
        "Denetimsiz Ã¶ÄŸrenme nedir?",
        "Veri kÃ¼mesi (dataset) nedir?",
        "Makine Ã¶ÄŸrenmesinde model ne demektir?",
        "Overfitting ne anlama gelir?",
        "DoÄŸruluk (accuracy) nasÄ±l hesaplanÄ±r?",
        "Makine Ã¶ÄŸrenmesinde eÄŸitim ve test verisi neden ayrÄ±lÄ±r?",
        "Lineer regresyon ne iÅŸe yarar?",
        "Scikit-learn hangi amaÃ§la kullanÄ±lÄ±r?",
        "KarmaÅŸÄ±k bir modelin Ã¶ÄŸrenmesi neden daha uzun sÃ¼rer?",
        "Hiperparametre nedir?",
        "Modelin doÄŸruluÄŸu nasÄ±l iyileÅŸtirilir?",
        "Veri temizleme neden Ã¶nemlidir?",
        "Ã–zellik mÃ¼hendisliÄŸi (feature engineering) nedir?",
        "Veri madenciliÄŸi (data mining) nedir?",
        "Yapay sinir aÄŸlarÄ± nasÄ±l Ã§alÄ±ÅŸÄ±r?",
        "Derin Ã¶ÄŸrenme nedir?",
        "Aktivasyon fonksiyonlarÄ± nelerdir?",
        "SÄ±nÄ±flandÄ±rma ve regresyon arasÄ±ndaki fark nedir?",
    ],
    "cevap": [
        "Makine Ã¶ÄŸrenmesi, veriden Ã¶ÄŸrenen algoritmalardÄ±r.",
        "Denetimli Ã¶ÄŸrenme, etiketli veriyle modeli eÄŸitmektir.",
        "Denetimsiz Ã¶ÄŸrenme, verideki yapÄ±larÄ± etiket olmadan keÅŸfetmektir.",
        "Veri kÃ¼mesi, modelin Ã¶ÄŸrenmesi iÃ§in kullanÄ±lan Ã¶rnekler topluluÄŸudur.",
        "Model, Ã¶ÄŸrenme sÃ¼reÃ§lerini kontrol eden yapÄ±dÄ±r.",
        "Overfitting, modelin veriye aÅŸÄ±rÄ± uyum saÄŸlamasÄ±dÄ±r.",
        "DoÄŸruluk, doÄŸru tahminlerin toplam tahminlere oranÄ±dÄ±r.",
        "EÄŸitim verisi, modelin Ã¶ÄŸrenmesini saÄŸlarken test verisi modelin doÄŸruluÄŸunu test eder.",
        "Lineer regresyon, sÃ¼rekli veriyle iliÅŸkiyi modellemeyi amaÃ§lar.",
        "Scikit-learn, Python'da makine Ã¶ÄŸrenmesi iÃ§in kullanÄ±lan bir kÃ¼tÃ¼phanedir.",
        "KarmaÅŸÄ±k modeller daha fazla parametreye sahip olduÄŸu iÃ§in daha fazla hesaplama gerektirir.",
        "Hiperparametre, modelin dÄ±ÅŸsal parametreleridir ve doÄŸru ayarlanmasÄ± gereklidir.",
        "Model doÄŸruluÄŸunu artÄ±rmak iÃ§in parametrelerin optimizasyonu ve veri iyileÅŸtirmesi yapÄ±labilir.",
        "Veri temizleme, hatalÄ± ve eksik verilerin dÃ¼zeltilmesidir ve modelin baÅŸarÄ±sÄ± iÃ§in Ã¶nemlidir.",
        "Ã–zellik mÃ¼hendisliÄŸi, ham verilerden anlamlÄ± Ã¶zellikler Ã§Ä±karmaktÄ±r.",
        "Veri madenciliÄŸi, bÃ¼yÃ¼k veri kÃ¼melerinden desenlerin ve iliÅŸkilerin Ã§Ä±karÄ±lmasÄ± sÃ¼recidir.",
        "Yapay sinir aÄŸlarÄ±, insan beynine benzer ÅŸekilde Ã§alÄ±ÅŸan Ã¶ÄŸrenme modelleridir.",
        "Derin Ã¶ÄŸrenme, Ã§ok katmanlÄ± yapÄ±larla veri analizini iÃ§eren bir makine Ã¶ÄŸrenmesi tÃ¼rÃ¼dÃ¼r.",
        "Aktivasyon fonksiyonlarÄ±, modelin Ã¶ÄŸrenme sÃ¼recinde doÄŸrusal olmayan Ã¶zellikler ekler.",
        "SÄ±nÄ±flandÄ±rma, veriyi kategorilere ayÄ±rÄ±rken regresyon sÃ¼rekli bir Ã§Ä±ktÄ±yÄ± tahmin eder.",
    ]
}

# Ä°lk kullanÄ±m iÃ§in verileri ekleme (bir kere Ã§alÄ±ÅŸtÄ±rÄ±lmalÄ±)
'''
if collection.count() == 0:
    print("VeritabanÄ± boÅŸ, Ã¶rnek veriler ekleniyor...")
    embeddings = model.encode(data["soru"]).tolist()
    ids = [f"id_{i}" for i in range(len(data["soru"]))]
    
    collection.add(
        documents=data["soru"],
        metadatas=[{"cevap": cevap} for cevap in data["cevap"]],
        embeddings=embeddings,
        ids=ids
    )
    print(f"{len(data['soru'])} adet soru-cevap Ã§ifti veritabanÄ±na eklendi.")
'''

# Yeni soru alma
while True:
    print("\n" + "="*50)
    print("1: Yeni soru sor")
    print("2: VeritabanÄ± durumunu gÃ¶ster")
    print("3: VeritabanÄ±nÄ± temizle")
    print("q: Ã‡Ä±kÄ±ÅŸ")
    secim = input("ğŸ”¹ SeÃ§iminiz: ").strip().lower()
    
    if secim == 'q':
        break
    elif secim == '1':
        yeni_soru = input("\nğŸ”¹ Yeni soruyu girin: ").strip()
        if not yeni_soru:
            continue
            
        yeni_soru_temiz = temizle_stopwords(yeni_soru)
        yeni_embedding = model.encode(yeni_soru_temiz).tolist()

        try:
            # Benzer sorgu - Daha fazla sonuÃ§ alÄ±p en iyisini seÃ§elim
            sonuc = collection.query(
                query_embeddings=[yeni_embedding],
                n_results=3  # Ä°lk 3 sonucu al
            )

            if sonuc["documents"] and len(sonuc["documents"][0]) > 0:
                # En iyi eÅŸleÅŸmeyi bul
                best_match_idx = 0
                best_similarity = 1 - sonuc["distances"][0][0]
                
                # DiÄŸer sonuÃ§larÄ± da kontrol et
                for i in range(1, len(sonuc["distances"][0])):
                    current_similarity = 1 - sonuc["distances"][0][i]
                    if current_similarity > best_similarity:
                        best_similarity = current_similarity
                        best_match_idx = i
                
                en_benzer_soru = sonuc["documents"][0][best_match_idx]
                en_benzer_cevap = sonuc["metadatas"][0][best_match_idx]["cevap"]
                
                
                if best_similarity > 0.7:  # EÅŸik deÄŸerini yÃ¼kselttim                   
                    print(f"\nEn benzer soru: {en_benzer_soru}")
                    print(f"\nCevap: {en_benzer_cevap}")
                    print(f"Benzerlik skoru: {best_similarity:.2f}")
                
                    # EÄŸer soru tam olarak aynÄ± deÄŸilse veritabanÄ±na ekle
                    if yeni_soru.lower() != en_benzer_soru.lower():
                        print("Soru benzer ama tam aynÄ± deÄŸil. Veri setine yeni varyasyon olarak eklendi.")
                        new_id = f"id_{collection.count()}"
                        collection.add(
                            documents=[yeni_soru],
                            metadatas=[{"cevap": en_benzer_cevap}],
                            embeddings=[yeni_embedding],
                            ids=[new_id]
                        )
                else:
                    print("\nğŸ§  Bu konuda yeterli bilgim yok. API'den yanÄ±t alÄ±nÄ±yor...")
                    yeni_cevap = API_ILE_CEVAP_AL(yeni_soru)
                    print(f"\nâœ¨ Yeni cevap: {yeni_cevap}")
                    
                    # Yeni soru-cevap Ã§iftini veritabanÄ±na ekle
                    new_id = f"id_{collection.count()}"
                    collection.add(
                        documents=[yeni_soru],
                        metadatas=[{"cevap": yeni_cevap}],
                        embeddings=[yeni_embedding],
                        ids=[new_id]
                    )
                    
        except Exception as e:
            print(f"\nHata oluÅŸtu: {e}")
            
    elif secim == '2':
        veritabani_kontrol(collection)
        
    elif secim == '3':
        onay = input("\nâš  TÃ¼m veritabanÄ± silinecek! Emin misiniz? (e/h): ").lower()
        if onay == 'e':
            if veritabani_temizle(chroma_client):
                # Koleksiyonu yeniden oluÅŸtur
                collection = chroma_client.get_or_create_collection(
                    name="soru_cevaplar",
                    metadata={"hnsw:space": "cosine"}
                )
                # Ã–rnek verileri yeniden yÃ¼kle
                if collection.count() == 0:
                    embeddings = model.encode(data["soru"]).tolist()
                    ids = [f"id_{i}" for i in range(len(data["soru"]))]
                    collection.add(
                        documents=data["soru"],
                        metadatas=[{"cevap": cevap} for cevap in data["cevap"]],
                        embeddings=embeddings,
                        ids=ids
                    )
                    print("\nâœ… Ã–rnek veriler yeniden yÃ¼klendi")
    else:
        print("GeÃ§ersiz seÃ§im, tekrar deneyin")

# Ä°stemciyi kapat (opsiyonel)
chroma_client.heartbeat()  # Son bir baÄŸlantÄ± testi
print("\nUygulama sonlandÄ±rÄ±ldÄ±")